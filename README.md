 # Document expliquant le projet
 Voici quelques suggestions SEO pour optimiser le contenu de votre site web d'Alaric Tabari√®s sur https://www.altab.fr :

Ajout de Mots-Cl√©s Pertinents : Bien que la description soit riche en d√©tails, ajouter des mots-cl√©s pertinents peut am√©liorer le SEO. Par exemple, des mots-cl√©s comme "science ouverte", "archivage scientifique", "lombricompostage", "compostage maison", "√©levage de cloportes", "nature et compostage", ou "pratiques √©cologiques" pourraient attirer un public plus cibl√©.

Optimisation des Balises Meta :

Meta Description : Actuellement, il n'y a pas de description unique. Une balise meta description plus concise, orient√©e SEO, pourrait √™tre :
"Explorez les recherches en science ouverte d'Alaric Tabari√®s, doctorant √† l‚ÄôUniversit√© de Toulon, et d√©couvrez ses exp√©riences en nature, compostage, lombricompostage, et cuisine."

Structuration du Contenu avec des Balises Hn :

Utiliser des balises de titres (H1, H2, H3) de mani√®re logique pour structurer le contenu, en cr√©ant une hi√©rarchie qui aide les moteurs de recherche √† comprendre les sections principales comme ¬´ √Ä propos ¬ª, ¬´ Travaux de recherche ¬ª, et ¬´ Nature et compostage ¬ª.
Liens Internes Optimis√©s :

Assurez-vous que les liens internes sont bien reli√©s aux pages pertinentes, ce qui favorisera une meilleure indexation par les moteurs de recherche.
Am√©liorer le Texte Alternatif pour les Images :

Ajouter des descriptions de texte alternatif pour chaque image, en incluant des mots-cl√©s pertinents, aidera √† am√©liorer le r√©f√©rencement des images sur les moteurs de recherche.
Contenu Actualis√© et Blog :

Publier r√©guli√®rement des articles sur des sujets li√©s √† vos recherches ou exp√©riences (par exemple, un article d√©taill√© sur le compostage ou l‚Äô√©levage de cloportes) pourrait attirer plus de visiteurs r√©currents et am√©liorer le r√©f√©rencement naturel.












import streamlit as st
import requests
from bs4 import BeautifulSoup
from urllib.parse import urljoin
import tempfile
import base64
import io
from selenium import webdriver
import time
from PIL import Image
import matplotlib.pyplot as plt
from wordcloud import WordCloud
import os

# Fonction pour r√©cup√©rer toutes les images d'une page web avec Selenium
def extraire_images_selenium(url):
    options = webdriver.ChromeOptions()
    options.add_argument("--headless")
    driver = webdriver.Chrome(options=options)
    driver.get(url)
    time.sleep(3)  # Attendre le chargement complet de la page
    soup = BeautifulSoup(driver.page_source, "html.parser")
    driver.quit()
    images = []
    for img in soup.find_all("img"):
        img_url = img.get("src")
        alt_text = img.get("alt", "Pas de texte alternatif")
        if img_url:
            full_url = urljoin(url, img_url) if not img_url.startswith("data:image") else img_url
            images.append({"URL": full_url, "Texte alternatif": alt_text})
    return images

# Fonction pour t√©l√©charger et convertir l'image
def telecharger_et_convertir_image(image_info):
    image_url = image_info["URL"]
    try:
        if image_url.startswith("data:image"):
            header, encoded = image_url.split(",", 1)
            image_bytes = base64.b64decode(encoded)
            image = Image.open(io.BytesIO(image_bytes))
        else:
            response = requests.get(image_url)
            response.raise_for_status()
            image = Image.open(io.BytesIO(response.content))

        image = image.convert("RGB")
        with tempfile.NamedTemporaryFile(delete=False, suffix=".png") as tmp_file:
            image.save(tmp_file, format="PNG")
            return tmp_file.name, image
    except Exception as e:
        return f"Erreur : {e}", None

# Fonction d‚Äôanalyse SEO basique des images
def analyse_seo_image(image_path, alt_text):
    try:
        image = Image.open(image_path)
        width, height = image.size
        file_size_kb = os.path.getsize(image_path) / 1024
        file_name = os.path.basename(image_path)

        # Crit√®res SEO
        recommendations = []
        
        if alt_text == "Pas de texte alternatif" or len(alt_text) < 5:
            recommendations.append("Ajouter un texte alternatif descriptif.")
        if width > 1200 or height > 1200:
            recommendations.append("Redimensionner l'image pour optimiser la taille (max 1200x1200).")
        if file_size_kb > 100:
            recommendations.append("R√©duire la taille du fichier (< 100KB recommand√©).")
        if not any(keyword in file_name.lower() for keyword in ["image", "img", "photo"]):
            recommendations.append("Renommer le fichier pour inclure des mots-cl√©s descriptifs.")

        return recommendations or ["Image optimis√©e pour le SEO."]
    except Exception as e:
        return [f"Erreur d'analyse de l'image : {e}"]

# Fonction pour extraire les donn√©es de la page
def extraire_donnees_page(url):
    try:
        response = requests.get(url, timeout=10)
        response.raise_for_status()
    except requests.exceptions.RequestException as e:
        st.error(f"Erreur lors de la requ√™te pour {url} : {e}")
        return None

    soup = BeautifulSoup(response.text, "html.parser")
    titre = soup.title.text if soup.title else "Pas de titre"
    meta_description = soup.find("meta", attrs={"name": "description"})
    meta_description = meta_description["content"] if meta_description else "Pas de description"
    meta_keywords = soup.find("meta", attrs={"name": "keywords"})
    meta_keywords = meta_keywords["content"] if meta_keywords else "Pas de mots-cl√©s"
    contenu = " ".join([p.text for p in soup.find_all("p")])
    images = extraire_images_selenium(url)

    return {
        "titre": titre,
        "meta_description": meta_description,
        "meta_keywords": meta_keywords,
        "contenu": contenu,
        "images": images,
    }

# Fonction pour visualiser les longueurs des √©l√©ments SEO avec Matplotlib
def visualiser_longueurs_seo(donnees_page):
    data = {
        "Titre": len(donnees_page["titre"]),
        "Description meta": len(donnees_page["meta_description"]),
        "Mots-cl√©s": len(donnees_page["meta_keywords"])
    }
    fig, ax = plt.subplots()
    ax.bar(data.keys(), data.values(), color=["skyblue", "salmon", "lightgreen"])
    ax.set_ylabel("Nombre de caract√®res")
    ax.set_title("Longueur des √©l√©ments SEO")
    st.pyplot(fig)

# Fonction pour cr√©er un nuage de mots pour les mots-cl√©s
def nuage_de_mots(mots_cles):
    mots = mots_cles.split(", ")
    texte = " ".join(mots)
    wordcloud = WordCloud(width=800, height=400, background_color="white").generate(texte)
    fig, ax = plt.subplots()
    ax.imshow(wordcloud, interpolation="bilinear")
    ax.axis("off")
    st.pyplot(fig)

# Fonction pour g√©n√©rer des recommandations SEO avec une API locale (Ollama ou autre)
def generer_seo_avec_ollama(donnees_page):
    try:
        model = "llama3.2:1b"  # Le mod√®le est maintenant explicitement pass√© ici
        prompt = f"""
        Voici les donn√©es SEO d'une page web :
        - Titre : {donnees_page['titre']}
        - Description meta : {donnees_page['meta_description']}
        - Mots-cl√©s : {donnees_page['meta_keywords']}
        - Contenu de la page : {donnees_page['contenu']}
        
        Veuillez fournir des recommandations SEO pour am√©liorer le contenu, l'utilisation des mots-cl√©s et les √©l√©ments de la page.
        """
        
        url = "http://127.0.0.1:5000/v1/completions"  # URL correcte de l'API
        headers = {"Content-Type": "application/json"}
        data = {"model": model, "prompt": prompt}  # Assurez-vous que le mod√®le est pass√© ici

        # Envoi de la requ√™te POST pour g√©n√©rer des recommandations SEO
        response = requests.post(url, json=data, headers=headers)

        if response.status_code == 200:
            try:
                recommandations = response.json().get("choices", [{}])[0].get("text", "Aucune recommandation g√©n√©r√©e.")
                return recommandations
            except Exception as e:
                return f"Erreur dans le traitement de la r√©ponse JSON : {e}"
        else:
            return f"Erreur lors de l'appel √† l'API : {response.status_code} - {response.text}"

    except requests.exceptions.RequestException as e:
        return f"Erreur de connexion √† l'API : {e}"

# Application Streamlit principale
st.title("üîç Analyse SEO et Visualisation")
url = st.text_input("Entrez l'URL de la page √† analyser", "https://www.exemple.com")

if st.button("Analyser"):
    donnees_page = extraire_donnees_page(url)
    if donnees_page:
        st.markdown("### üìù Informations de base")
        st.markdown(f"**Titre** : {donnees_page['titre']}")
        st.markdown(f"**Description meta** : {donnees_page['meta_description']}")
        st.markdown(f"**Mots-cl√©s** : {donnees_page['meta_keywords']}")

        # Visualisation des longueurs des champs SEO
        st.markdown("### üìä Longueur des √©l√©ments SEO")
        visualiser_longueurs_seo(donnees_page)

        # Nuage de mots pour les mots-cl√©s
        if donnees_page["meta_keywords"] != "Pas de mots-cl√©s":
            st.markdown("### üå•Ô∏è Nuage de mots des mots-cl√©s")
            nuage_de_mots(donnees_page["meta_keywords"])
        else:
            st.write("Aucun mot-cl√© trouv√©.")

        # Analyse et affichage des images avec recommandations SEO dans des expanders
        st.markdown("### üñºÔ∏è Analyse d'images et recommandations SEO")
        for image_info in donnees_page["images"]:
            image_url = image_info.get("URL", "URL indisponible")
            image_path, image = telecharger_et_convertir_image(image_info)
            recommandations = analyse_seo_image(image_path, image_info["Texte alternatif"])
            
            with st.expander(f"Image : {image_url}") :
                col1, col2 = st.columns([1, 2])
                with col1:
                    if image:
                        st.image(image, width=150)
                    else:
                        st.write("Image non disponible")
                with col2:
                    st.markdown(f"**URL de l'image :** {image_url}")
                    st.markdown(f"**Texte alternatif :** {image_info['Texte alternatif']}")
                    st.markdown("**Recommandations SEO :**")
                    for rec in recommandations:
                        st.markdown(f"- {rec}")

        # Recommandations SEO avec Ollama
        st.markdown("### üõ†Ô∏è Recommandations SEO personnalis√©es")
        recommandations = generer_seo_avec_ollama(donnees_page)
        st.markdown(f"**Recommandations :** {recommandations}")

        # Insights SEO suppl√©mentaires
        st.markdown("---")
        st.markdown("### üìä Insights SEO suppl√©mentaires")
        st.markdown("**Compatibilit√© mobile et optimisation de la vitesse**")
        st.write("Pour un rapport de compatibilit√© mobile et des recommandations de vitesse, utilisez un outil tel que Google PageSpeed Insights.")
